1、hdfs：
namenode 37
snamenode 38
datanode 38


2、yarn:
resourcemanager 37
nodemanager 37 38

3、hive:
hiveserver2 37
hive metastore 38
webhcat server 37

4、spark
history server：37

安装的服务一般在/usr/hadoop里。

5、notebook

10.10.77.137 安装了anaconda
10.10.77.137 安装了zeppelin 9994 不能使用spark

可以使用spark
10.10.99.38 安装了ambrari的zeppelin 不能使用Python
10.10.99.37 安装了zeppelin 可以使用python